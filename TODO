# better naming coerce <-> coercion (balance types?)
# compile boolean operations, compile Convolve#demand
# Composite numbers?
# pointer-increments for better efficiency
# How does contiguous work here? typecasts?
# Plus#demand: @value1.demand + @value2.demand ???
# nonzero?
# typecasts
# preload cache
# separate secondary operations like equality
# inject without initial is [ 1 .. -1 ].inject with [ 0 ] as initial value

# histogram
# inject: min, max, equal, n-d clips for warp
# block(var1,var2,...) with smart subst?
# lazy( 5 ) { |i| 0 } # but lazy { 0 }
# lazy( 3, 2 ) { |i,j| i }
# lazy( 3, 2 ) { |i,j| j.to_object }

# downsampling after correlation?
# README.rdoc, YARD documentation with pictures, demo video

# f(g(i)) # g(i), f(g(i)) all can be vectors and all can be lazy
# lut(g(i))
# f(warp(i))
#class Node
#  def map( lut, options = {} )
#    
#  end
#end


# cache <-> demand/get? what about store?
# Composite numbers?
# change Convolve#demand to generate GCC code
# inspect method (type method to get MultiArray( ... ) or Sequence( ... ))
# put JIT-calls into 'force'-method, don't call JIT for OBJECT
# -> multiarray gem
# pointer-increments for better efficiency
# use pid, allow creation of library for pre-loading cache

# histogram
# binary operations, equality: ( a == b ).inject( true ) { |e,b| e && b }
# inject: min, max, equal, n-d clips for warp
# block(var1,var2,...) with smart subst?
# lazy( 5 ) { |i| 0 }
# lazy( 3, 2 ) { |i,j| i }
# lazy( 3, 2 ) { |i,j| j }

# downsampling after correlation?
# ruby -Ilib -rrubygems -rmultiarray -rtest test/tc_sequence.rb
# README.rdoc, demo video

# f(g(i)) # g(i), f(g(i)) all can be vectors and all can be lazy
# lut(g(i))
# f(warp(i))
#class Node
#  def map( lut, options = {} ) # !!!
#    
#  end
#end


lazy { a * b } -> lazy { |i,j| lazy { |i,j| a[i,j] * b[i,j] }[i,j] } # ?
lazy { s } -> s
lazy { -s } -> lazy { |i| -s[i] }
lazy { |i,j| s[i,j] }
lazy { |i| lazy { |j| s[i,j] } }
lazy( n ) { |i| i }
lazy( n, m ) { |i,j| i + j }
lazy( n ) { |i| lazy( m ) { |j| i + j } }
eager( n ) { |i| i }
...

tensor indices to enable transpose of lazy array
ranges (rolling, lazy rolling, lazy ranges)
test lazyness
sums/injections (equality for arrays)? nesting? tensors?
JIT?
test type conversions
fancy README

a = lazy( 16 ) { |i| i }
a = lazy( 16 ) { |i| i }[ 4 ... 12 ]  # offsets: apply sel-operation to all
                                        members; index array?
a = lazy( 16, 32 ) { |i,j| Sequence[ i, j ] } # ???
a = lazy( 8, 8 ) { |i,j| Sequence[ i, a[j] * sin( i + b[j] ) ] }.hist 8, 8
a = b.class.new.op { |x| set -x }
a = lazy { |i| -b[i] }
a = lazy { -b }
a = array { -b }
a = array { |i| -b[i] }
a = array( :dim => [ b.size ] ) { |i| -b[i] }
a = -b
array { |i| sum { |j| a[i,j] } }
lazy { |i| sum { |j| a[i,j] } }
parallel { ... }
lazy { |i| lazy { |j| a[i,j] } }
array { lazy { |i| sum { |j| a[i,j] } } }

correlate?

lines:
[ i, a[j] * sin( i + b[j] ) ].hist

lines:
lazy { |i,j| i.zip( a[j] * sin( i + b[j] ) ) }.histogram 32, 20

lines:
lazy { |i,j| Sequence[ i, a[j] * sin( i + b[j] ) ] }.histogram 32, 20
combined histograms?

circle:
[ sin( i ) * r, cos( i ) * r ].hist

Geometric Hashing? Bounded Hough Transform!!! RANSAC? histogram weights?

array: lazy retrieval? jit code for address computation
OBJECT: object with type information
Lazy( Sequence( INT, 3 ) )

interpretation: type coercion, actual operation, jit,
collection of jit arguments (e.g. tensor)

proc { |i| proc { |j| i+j } }.call( 5 ).call 3

gem install flay: http://ruby.sadi.st/Flay.html

# donate to yardoc

How to nest/cascade mode-environments?
(how to specify nested modes for recursive algorithms and called algorithms?)
ruby and jit compiles, lazy and parallel forwards

* Ruby
* Lazy (Lazy histogram -> hough transform, lazy transpose, unused indices?)
* Multithreading
* JIT
* GCC
