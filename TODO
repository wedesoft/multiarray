# compile Diagonal#demand, optimize Node#diagonal
include Hornetseye
m = MultiArray[ [ 'a1', 'a2', 'a3' ], [ 'b1', 'b2', 'b3' ], [ 'c1', 'c2', 'c3' ] ]
m.diagonal { |a,b| a + b } # [ "b1a2", "c1b2a3", "c2b3" ]

m = MultiArray[ [ 'a1', 'a2', 'a3', 'a4' ], [ 'b1', 'b2', 'b3', 'b4' ], [ 'c1', 'c2', 'c3', 'c4' ] ]
m.diagonal { |a,b| a + b } # [ "c1b2a3", "c2b3a4", "c3b4" ]

m = MultiArray[ [ 'a1', 'a2', 'a3' ], [ 'b1', 'b2', 'b3' ], [ 'c1', 'c2', 'c3' ], [ 'd1', 'd2', 'd3' ] ]
m.diagonal { |a,b| a + b } # [ "b1a2", "c1b2a3", "d1c2b3", "d2c3" ]

# Sequence[ 0, 1, 0 ].convolve Sequence[ 1, 2, 3 ]
# MultiArray[ [ 1, 2, 3 ], [ 4, 5, 6 ], [ 7, 8, 9 ] ].diagonal { |a,b| a + b }
# unify lookup and skip?
# Composite numbers?
# pointer-increments for better efficiency
# implement typecasts, how does contiguous work here?
# separate secondary operations like equality
# inject without initial is [ 1 .. -1 ].inject with [ 0 ] as initial value

# histogram (implement using injection)
# inject: min, max, equal, n-d clips for warp
# block(var1,var2,...) with smart subst?
# lazy( 3, 2 ) { |i,j| j.to_object }

# RSpec

# downsampling after correlation?
# YARD documentation with pictures, demo video
# CK_Thesis.pdf: tensor voting

# f(g(i)) # g(i), f(g(i)) all can be vectors and all can be lazy
# lut(g(i))
# f(warp(i))
#class Node
#  def map( lut, options = {} )
#    
#  end
#end


# cache <-> demand/get? what about store?
# Composite numbers?
# change Convolve#demand to generate GCC code
# inspect method (type method to get MultiArray( ... ) or Sequence( ... ))
# put JIT-calls into 'force'-method, don't call JIT for OBJECT
# -> multiarray gem
# pointer-increments for better efficiency
# use pid, allow creation of library for pre-loading cache

# histogram
# binary operations, equality: ( a == b ).inject( true ) { |e,b| e && b }
# inject: min, max, equal, n-d clips for warp
# block(var1,var2,...) with smart subst?

# downsampling after correlation?
# ruby -Ilib -rrubygems -rmultiarray -rtest test/tc_sequence.rb
# README.rdoc, demo video

# f(g(i)) # g(i), f(g(i)) all can be vectors and all can be lazy
# lut(g(i))
# f(warp(i))
#class Node
#  def map( lut, options = {} ) # !!!
#    
#  end
#end

ranges (rolling, lazy rolling, lazy ranges)
test type conversions

a = lazy( 16, 32 ) { |i,j| Sequence[ i, j ] } # ???
a = lazy( 8, 8 ) { |i,j| Sequence[ i, a[j] * sin( i + b[j] ) ] }.hist 8, 8
parallel { ... }

lines:
[ i, a[j] * sin( i + b[j] ) ].hist

lines:
lazy { |i,j| i.zip( a[j] * sin( i + b[j] ) ) }.histogram 32, 20

lines:
lazy { |i,j| Sequence[ i, a[j] * sin( i + b[j] ) ] }.histogram 32, 20
combined histograms?

circle:
[ sin( i ) * r, cos( i ) * r ].hist

Geometric Hashing? Bounded Hough Transform!!! RANSAC? histogram weights?

array: lazy retrieval? jit code for address computation
OBJECT: object with type information
Lazy( Sequence( INT, 3 ) )

interpretation: type coercion, actual operation, jit,
collection of jit arguments (e.g. tensor)
